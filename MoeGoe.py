import gradio as gr
from scipy.io.wavfile import write
from mel_processing import spectrogram_torch
from text import text_to_sequence, _clean_text
from models import SynthesizerTrn
import utils
import commons
import torch
import re
import os
import tempfile
import logging
from torch import no_grad, LongTensor
import numpy as np

logging.getLogger('numba').setLevel(logging.WARNING)

# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹å’Œé…ç½®
model_global = None
hps_global = None
speakers_global = []
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def load_model(model_path, config_path):
    """åŠ è½½VITSæ¨¡å‹å’Œé…ç½®"""
    global model_global, hps_global, speakers_global
    
    try:
        # åŠ è½½é…ç½®
        hps = utils.get_hparams_from_file(config_path)
        
        # è·å–è¯´è¯äººåˆ—è¡¨
        speakers = hps.speakers if 'speakers' in hps.keys() else ['0']
        n_speakers = hps.data.n_speakers if 'n_speakers' in hps.data.keys() else 0
        n_symbols = len(hps.symbols) if 'symbols' in hps.keys() else 0
        
        # åˆå§‹åŒ–æ¨¡å‹
        net_g = SynthesizerTrn(
            n_symbols,
            hps.data.filter_length // 2 + 1,
            hps.train.segment_size // hps.data.hop_length,
            n_speakers=n_speakers,
            **hps.model).to(device)
        
        net_g.eval()
        utils.load_checkpoint(model_path, net_g, None)
        
        # ä¿å­˜åˆ°å…¨å±€å˜é‡
        model_global = net_g
        hps_global = hps
        speakers_global = speakers
        
        return f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼å‘ç° {len(speakers)} ä¸ªè¯´è¯äºº"
    
    except Exception as e:
        return f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}"

def get_speaker_list():
    """è·å–è¯´è¯äººåˆ—è¡¨ä¾›ä¸‹æ‹‰æ¡†ä½¿ç”¨"""
    if speakers_global:
        return [(name, idx) for idx, name in enumerate(speakers_global)]
    return [("æ— è¯´è¯äºº", 0)]

def process_text(text, length_scale, noise_scale, noise_scale_w):
    """å¤„ç†æ–‡æœ¬ä¸­çš„æ§åˆ¶æ ‡ç­¾"""
    if text is None or text == "":
        return None, "è¯·è¾“å…¥æ–‡æœ¬"
    
    # æå–æ§åˆ¶æ ‡ç­¾
    length_scale, text = get_label_value(text, 'LENGTH', length_scale, 'length scale')
    noise_scale, text = get_label_value(text, 'NOISE', noise_scale, 'noise scale')
    noise_scale_w, text = get_label_value(text, 'NOISEW', noise_scale_w, 'deviation of noise')
    cleaned, text = get_label(text, 'CLEANED')
    
    return text, length_scale, noise_scale, noise_scale_w, cleaned

def get_label_value(text, label, default, warning_name='value'):
    """ä»æ–‡æœ¬ä¸­æå–æ ‡ç­¾å€¼"""
    value = re.search(rf'\[{label}=(.+?)\]', text)
    if value:
        try:
            text = re.sub(rf'\[{label}=(.+?)\]', '', text, 1)
            value = float(value.group(1))
        except:
            print(f'Invalid {warning_name}!')
            value = default
    else:
        value = default
    return value, text

def get_label(text, label):
    """ä»æ–‡æœ¬ä¸­æå–å¸ƒå°”æ ‡ç­¾"""
    if f'[{label}]' in text:
        return True, text.replace(f'[{label}]', '')
    else:
        return False, text

def get_text(text, cleaned=False):
    """å°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥"""
    if hps_global is None:
        return None
    
    if cleaned:
        text_norm = text_to_sequence(text, hps_global.symbols, [])
    else:
        text_norm = text_to_sequence(text, hps_global.symbols, hps_global.data.text_cleaners)
    
    if hps_global.data.add_blank:
        text_norm = commons.intersperse(text_norm, 0)
    
    text_norm = LongTensor(text_norm).to(device)
    return text_norm

def synthesize(text, speaker_id, length_scale, noise_scale, noise_scale_w, 
               model_path, config_path, output_path):
    """åˆæˆè¯­éŸ³çš„ä¸»å‡½æ•°"""
    
    # æ£€æŸ¥æ˜¯å¦å·²åŠ è½½æ¨¡å‹
    if model_global is None or hps_global is None:
        if not model_path or not config_path:
            return None, "è¯·å…ˆé€‰æ‹©æ¨¡å‹å’Œé…ç½®æ–‡ä»¶"
        load_result = load_model(model_path, config_path)
        if "âŒ" in load_result:
            return None, load_result
    
    try:
        # å¤„ç†æ–‡æœ¬
        processed_text, length_scale, noise_scale, noise_scale_w, cleaned = process_text(
            text, length_scale, noise_scale, noise_scale_w
        )
        
        if processed_text is None:
            return None, "è¯·è¾“å…¥æ–‡æœ¬"
        
        # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥
        stn_tst = get_text(processed_text, cleaned=cleaned)
        if stn_tst is None:
            return None, "æ–‡æœ¬å¤„ç†å¤±è´¥"
        
        # æ¨ç†
        with no_grad():
            x_tst = stn_tst.unsqueeze(0)
            x_tst_lengths = LongTensor([stn_tst.size(0)]).to(device)
            sid = LongTensor([speaker_id]).to(device)
            
            audio = model_global.infer(
                x_tst, x_tst_lengths, sid=sid,
                noise_scale=noise_scale,
                noise_scale_w=noise_scale_w,
                length_scale=length_scale
            )[0][0, 0].data.cpu().float().numpy()
        
        # ä¿å­˜éŸ³é¢‘
        if not output_path:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_dir = tempfile.gettempdir()
            output_path = os.path.join(temp_dir, "vits_output.wav")
        
        write(output_path, hps_global.data.sampling_rate, audio)
        
        return output_path, f"âœ… åˆæˆæˆåŠŸï¼éŸ³é¢‘å·²ä¿å­˜åˆ°ï¼š{output_path}\nä½¿ç”¨å‚æ•°ï¼šé•¿åº¦ç¼©æ”¾={length_scale:.2f}, å™ªå£°={noise_scale:.2f}, å™ªå£°åå·®={noise_scale_w:.2f}"
    
    except Exception as e:
        return None, f"âŒ åˆæˆå¤±è´¥ï¼š{str(e)}"

def update_speaker_dropdown(model_path, config_path):
    """æ›´æ–°è¯´è¯äººä¸‹æ‹‰æ¡†"""
    if model_path and config_path:
        result = load_model(model_path, config_path)
        if "âœ…" in result:
            speakers = get_speaker_list()
            return gr.Dropdown(choices=speakers, value=0), result
        else:
            return gr.Dropdown(choices=[("æ— è¯´è¯äºº", 0)], value=0), result
    return gr.Dropdown(choices=[("è¯·å…ˆåŠ è½½æ¨¡å‹", 0)], value=0), "è¯·é€‰æ‹©æ¨¡å‹å’Œé…ç½®æ–‡ä»¶"

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="VITS TTS GUI", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ¤ VITS æ–‡æœ¬è½¬è¯­éŸ³ GUI
    
    åŸºäºVITSçš„æ–‡æœ¬åˆæˆè¯­éŸ³ç•Œé¢ï¼Œæ”¯æŒå¤šç§å‚æ•°è°ƒèŠ‚ã€‚
    """)
    
    with gr.Row():
        with gr.Column(scale=1):
            # æ¨¡å‹é…ç½®åŒº
            gr.Markdown("### ğŸ“ æ¨¡å‹é…ç½®")
            model_path = gr.File(
                label="é€‰æ‹©VITSæ¨¡å‹æ–‡ä»¶ (.pth)",
                file_types=[".pth"],
                type="filepath"
            )
            config_path = gr.File(
                label="é€‰æ‹©é…ç½®æ–‡ä»¶ (.json)",
                file_types=[".json"],
                type="filepath"
            )
            
            load_btn = gr.Button("ğŸ”„ åŠ è½½æ¨¡å‹", variant="primary")
            load_status = gr.Textbox(label="åŠ è½½çŠ¶æ€", interactive=False)
            
            gr.Markdown("### ğŸ›ï¸ åˆæˆå‚æ•°")
            length_scale = gr.Slider(
                minimum=0.1, maximum=2.0, value=1.0, step=0.1,
                label="é•¿åº¦ç¼©æ”¾ (LENGTH)",
                info="æ§åˆ¶è¯­é€Ÿï¼Œå€¼è¶Šå¤§è¯­é€Ÿè¶Šæ…¢"
            )
            noise_scale = gr.Slider(
                minimum=0.1, maximum=1.5, value=0.667, step=0.1,
                label="å™ªå£°ç¼©æ”¾ (NOISE)",
                info="æ§åˆ¶éšæœºæ€§ï¼Œå€¼è¶Šå¤§å˜åŒ–è¶Šå¤§"
            )
            noise_scale_w = gr.Slider(
                minimum=0.1, maximum=1.5, value=0.8, step=0.1,
                label="å™ªå£°åå·® (NOISEW)",
                info="æ§åˆ¶éŸ³è°ƒå˜åŒ–"
            )
        
        with gr.Column(scale=2):
            # è¾“å…¥è¾“å‡ºåŒº
            gr.Markdown("### ğŸ“ æ–‡æœ¬è¾“å…¥")
            text_input = gr.Textbox(
                label="è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬",
                placeholder="ä¾‹å¦‚ï¼š[LENGTH=1.2][NOISE=0.5]ä½ å¥½ï¼Œä¸–ç•Œï¼",
                lines=5
            )
            
            gr.Markdown("### ğŸ—£ï¸ è¯´è¯äººé€‰æ‹©")
            speaker_dropdown = gr.Dropdown(
                choices=[("è¯·å…ˆåŠ è½½æ¨¡å‹", 0)],
                value=0,
                label="é€‰æ‹©è¯´è¯äººID",
                info="ä»ä¸‹æ‹‰åˆ—è¡¨ä¸­é€‰æ‹©è¯´è¯äºº"
            )
            
            gr.Markdown("### ğŸ’¾ è¾“å‡ºè®¾ç½®")
            output_path = gr.Textbox(
                label="è¾“å‡ºéŸ³é¢‘è·¯å¾„",
                placeholder="ä¾‹å¦‚ï¼šoutput.wavï¼ˆç•™ç©ºåˆ™ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ï¼‰",
                value=""
            )
            
            synthesize_btn = gr.Button("ğŸ”Š åˆæˆè¯­éŸ³", variant="primary", size="lg")
            
            with gr.Row():
                audio_output = gr.Audio(
                    label="åˆæˆç»“æœ",
                    type="filepath"
                )
            
            output_status = gr.Textbox(label="åˆæˆçŠ¶æ€", interactive=False)

    # ç¤ºä¾‹åŒº
    gr.Markdown("### ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹")
    
    with gr.Row():
        example1 = gr.Button("ç¤ºä¾‹1ï¼šåŸºæœ¬åˆæˆ")
        example2 = gr.Button("ç¤ºä¾‹2ï¼šè°ƒæ•´è¯­é€Ÿ")
        example3 = gr.Button("ç¤ºä¾‹3ï¼šå¢åŠ éšæœºæ€§")
        example4 = gr.Button("ç¤ºä¾‹4ï¼šç»„åˆå‚æ•°")
    
    gr.Markdown("""
    **è¾“å…¥æ ¼å¼è¯´æ˜ï¼š**
    - `[LENGTH=1.2]` - è®¾ç½®è¯­é€Ÿï¼ˆé»˜è®¤1.0ï¼‰
    - `[NOISE=0.5]` - è®¾ç½®å™ªå£°ï¼ˆé»˜è®¤0.667ï¼‰
    - `[NOISEW=0.9]` - è®¾ç½®å™ªå£°åå·®ï¼ˆé»˜è®¤0.8ï¼‰
    - `[CLEANED]` - ä½¿ç”¨å·²æ¸…æ´—æ–‡æœ¬
    
    **å®Œæ•´ç¤ºä¾‹ï¼š** `[LENGTH=1.2][NOISE=0.5][NOISEW=0.9]ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨VITSï¼`
    """)
    
    # äº‹ä»¶ç»‘å®š
    load_btn.click(
        fn=update_speaker_dropdown,
        inputs=[model_path, config_path],
        outputs=[speaker_dropdown, load_status]
    )
    
    synthesize_btn.click(
        fn=synthesize,
        inputs=[
            text_input, speaker_dropdown,
            length_scale, noise_scale, noise_scale_w,
            model_path, config_path, output_path
        ],
        outputs=[audio_output, output_status]
    )
    
    # ç¤ºä¾‹ç‚¹å‡»äº‹ä»¶
    example1.click(
        fn=lambda: ("ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨VITSè¯­éŸ³åˆæˆï¼", 1.0, 0.667, 0.8),
        outputs=[text_input, length_scale, noise_scale, noise_scale_w]
    )
    
    example2.click(
        fn=lambda: ("[LENGTH=1.5]è¿™æ˜¯ä¸€ä¸ªè¯­é€Ÿè¾ƒæ…¢çš„ç¤ºä¾‹", 1.5, 0.667, 0.8),
        outputs=[text_input, length_scale, noise_scale, noise_scale_w]
    )
    
    example3.click(
        fn=lambda: ("[NOISE=1.2]è¿™æ˜¯ä¸€ä¸ªéšæœºæ€§è¾ƒå¼ºçš„ç¤ºä¾‹", 1.0, 1.2, 0.8),
        outputs=[text_input, length_scale, noise_scale, noise_scale_w]
    )
    
    example4.click(
        fn=lambda: ("[LENGTH=0.8][NOISE=0.9][NOISEW=1.1]è¿™æ˜¯ä¸€ä¸ªç»„åˆå‚æ•°çš„ç¤ºä¾‹", 0.8, 0.9, 1.1),
        outputs=[text_input, length_scale, noise_scale, noise_scale_w]
    )

# å¯åŠ¨ç•Œé¢
if __name__ == "__main__":
    demo.launch(
        server_name="127.0.0.1",
        server_port=7860,
        share=True,
        show_error=True
    )
